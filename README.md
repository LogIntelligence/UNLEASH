# UNLEASH: SOTA Semantic-based Log Parser with Pre-trained Language Models

__UNLEASH__ is and end-to-end semantic-based log parsing framework. This repository includes artifacts for reuse and reproduction of experimental results presented in our ICSE'25 paper titled _"Unleashing the True Potential of Semantic-based Log Parsing with Pre-trained Language Models"_.

__Table of Contents__
- [Repository Structure](#repository-structure)
- [Installation Instruction](#installation-instruction)
    - [Install Python 3.9](#install-python-39)
    - [Clone UNLEASH from GitHub](#clone-unleash-from-github)
    - [Create and activate a virtual environment](#create-and-activate-a-virtual-environment)
    - [Install UNLEASH from PyPI or Build from source](#install-unleash-from-pypi-or-build-from-source)
    - [Test the installation](#test-the-installation)
- [To run the code](#to-run-the-code)
- [Reproducibility](#reproducibility)
    - [RQ1 - Parsing Efficaicy](#rq1---parsing-efficaicy)
    - [RQ2 - Scalability and Generalization](#rq2---scalability-and-generalization)
    - [RQ3-5 - The Impact of Enhancement Mechanisms](#rq3---the-impact-of-enhancement-mechanisms)

- [Download Paper](#download-paper)
- [Citation](#citation)
- [Contact](#contact)

## Repository Structure

There are three main components in the repository:
1. `datasets`: Contains the log datasets used in the experiments.
2. `examples`: Contains the scripts to run the experiments.
3. `unleash`: Contains the implementation of UNLEASH.

<details>
<Summary>The main structure of the repository would look like this</Summary>

```
ðŸ“¦ UNLEASH
â”œâ”€Â LICENSE
â”œâ”€Â README.md
â”œâ”€Â datasets
â”‚Â Â â””â”€Â loghub-2.0
â”‚Â Â Â Â Â â”œâ”€Â Apache
â”‚Â Â Â Â Â â”‚Â Â â”œâ”€Â Apache_full.log
â”‚Â Â Â Â Â â”‚Â Â â”œâ”€Â Apache_full.log_structured.csv
â”‚Â Â Â Â Â â”‚Â Â â”œâ”€Â Apache_full.log_structured_corrected.csv
â”‚Â Â Â Â Â â”‚Â Â â”œâ”€Â Apache_full.log_templates.csv
â”‚Â Â Â Â Â â”‚Â Â â””â”€Â Apache_full.log_templates_corrected.csv
â”‚Â Â Â Â Â â”œâ”€Â ...
â”œâ”€Â docs
â”‚Â Â â”œâ”€Â CL.png
â”‚Â Â â”œâ”€Â Ob2_res.png
â”‚Â Â â”œâ”€Â Ob3_res.png
â”‚Â Â â”œâ”€Â RESULTS.md
â”‚Â Â â””â”€Â S_test_1.png
â”œâ”€Â environment.yml
â”œâ”€Â examples
â”‚Â Â â”œâ”€Â 01_sampling.py
â”‚Â Â â”œâ”€Â 02_run_unleash.py
â”‚Â Â â”œâ”€Â 03_evaluation.py
â”‚Â Â â”œâ”€Â benchmark.py
â”‚Â Â â””â”€Â config.py
â”œâ”€Â requirements.txt
â”œâ”€Â setup.py
â”œâ”€Â tests
â”‚Â Â â””â”€Â test.py
â””â”€Â unleash
Â Â Â â”œâ”€Â __init__.py
Â Â Â â”œâ”€Â arguments.py
Â Â Â â”œâ”€Â data
Â Â Â â”‚Â Â â”œâ”€Â __init__.py
Â Â Â â”‚Â Â â”œâ”€Â data_loader.py
Â Â Â â”‚Â Â â””â”€Â utils.py
Â Â Â â”œâ”€Â evaluation
Â Â Â â”‚Â Â â”œâ”€Â settings.py
Â Â Â â”‚Â Â â””â”€Â utils
Â Â Â â”‚Â Â Â Â Â â”œâ”€Â GA_calculator.py
Â Â Â â”‚Â Â Â Â Â â”œâ”€Â PA_calculator.py
Â Â Â â”‚Â Â Â Â Â â”œâ”€Â common.py
Â Â Â â”‚Â Â Â Â Â â”œâ”€Â evaluator_main.py
Â Â Â â”‚Â Â Â Â Â â”œâ”€Â oracle_template_correction.py
Â Â Â â”‚Â Â Â Â Â â”œâ”€Â post_process.py
Â Â Â â”‚Â Â Â Â Â â”œâ”€Â postprocess.py
Â Â Â â”‚Â Â Â Â Â â””â”€Â template_level_analysis.py
Â Â Â â”œâ”€Â models
Â Â Â â”‚Â Â â”œâ”€Â __init__.py
Â Â Â â”‚Â Â â”œâ”€Â base.py
Â Â Â â”‚Â Â â”œâ”€Â deberta.py
Â Â Â â”‚Â Â â””â”€Â roberta.py
Â Â Â â”œâ”€Â parsing_base.py
Â Â Â â”œâ”€Â parsing_cache.py
Â Â Â â”œâ”€Â postprocess.py
Â Â Â â”œâ”€Â sampling
Â Â Â â”‚Â Â â”œâ”€Â __init__.py
Â Â Â â”‚Â Â â”œâ”€Â entropy_sampling.py
Â Â Â â”‚Â Â â”œâ”€Â lilac_sampling.py
Â Â Â â”‚Â Â â”œâ”€Â logppt_sampling.py
Â Â Â â”‚Â Â â””â”€Â utils.py
Â Â Â â””â”€Â tuning
Â Â Â Â Â Â â”œâ”€Â __init__.py
Â Â Â Â Â Â â”œâ”€Â early_stopping.py
Â Â Â Â Â Â â”œâ”€Â trainer.py
Â Â Â Â Â Â â””â”€Â utils.py
```
</details>


## Installation Instruction
The code is implemented in Python 3.9.

### Install Python 3.9
We recommend using Python 3.9+ to run the code.
```bash
sudo apt update
sudo apt install python3.9 python3.9-venv python3.9-dev
```

### Clone UNLEASH from GitHub

```bash
git clone https://github.com/LogIntelligence/UNLEASH.git && cd UNLEASH
```

### Create and activate a virtual environment
We recommend creating a virtual environment to run the code.
```bash
python3.9 -m venv env
source env/bin/activate
```

### Install UNLEASH from PyPI or Build from source
You can install UNLEASH from PyPI or build from source.
```bash
# Install from PyPI
pip install unleash

# Build from source
pip install -e .
```

### Test the installation
```bash
pytest tests/test.py
```

<details>
<Summary>Expected output</Summary>

```bash
============================= test session starts ==============================
platform linux -- Python 3.9.7, pytest-6.2.5, pluggy-1.0.0
rootdir: /home/username/UNLEASH
collected 1 item

tests/test.py .                                                         [100%]

============================== 1 passed in 0.01s ===============================
```
</details>

## To run the code
### Download the data
Download the log datasets from [Loghub](https://zenodo.org/records/8275861) and extract them in the `datasets/loghub-2.0` folder.

### 1. Run sampling for a specific dataset
Set the `data_dir` variable in the `01_sampling.py` file to the path of the loghub-2.0 folder and the `output_dir` variable to the path where you want to save the sampled data.
Then run the following command:

```bash
cd examples
python 01_sampling.py Apache
```

### 2. Run UNLEASH on a specific dataset
```bash
cd examples
export dataset=Apache
python 02_run_unleash.py --log_file ../datasets/loghub-2.0/$dataset/${dataset}_full.log_structured.csv --model_name_or_path roberta-base --train_file ../datasets/loghub-2.0/$dataset/samples/entropy_32.json --validation_file ../datasets/loghub-2.0/$dataset/validation.json --dataset_name $dataset --parsing_num_processes 1 --output_dir ../results --max_train_steps 1000
```
Set `parsing_num_processes` to the number of CPU cores you want to use for parsing. The results will be saved in the `results` folder.

### 3. Evaluate Unleash on a specific dataset
```bash
cd examples
export dataset=Apache
python 03_evaluation.py --output_dir ../results --dataset $dataset
```
